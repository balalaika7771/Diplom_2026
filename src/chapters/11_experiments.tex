\chapter{Экспериментальное исследование}

\section{Методика экспериментов}

\subsection{Тестовая среда и инфраструктура}

Эксперименты проводились на тестовом кластере Kubernetes, развёрнутом на базе трёх физических серверов (Intel Xeon E5-2680 v4, 64 ГБ RAM каждый). Кластер включал 10 микросервисов, реализующих типовую e-commerce платформу: API Gateway, Auth Service, Catalog Service, Order Service, Payment Service, Notification Service, Inventory Service, Search Service, Analytics Service и Recommendation Service \cite{burns_kubernetes,kubernetes_docs}.

Стек наблюдаемости включал: Prometheus 2.47 для сбора метрик (интервал scrape 15~с), Elasticsearch 8.10 для агрегации логов, Jaeger 1.50 для трейсинга, Kafka 3.6 как шину событий между модулями агента \cite{prometheus_docs,grafana_docs,opentelemetry_docs}.

\subsection{Данные: источники, объём, подготовка}

Данные для экспериментов формировались из двух источников:

\begin{enumerate}
    \item \textbf{Синтетическая нагрузка} (70\% экспериментов). Генератор нагрузки на базе Locust воспроизводил паттерны пользовательского трафика: базовая нагрузка 500 req/s с пиками до 2000 req/s по расписанию. Инциденты инжектировались через Chaos Mesh \cite{chaos_engineering}: kill pod, network partition, CPU stress, memory leak, disk I/O saturation. Для каждого типа инцидента генерировалось по 50 экземпляров с варьированием интенсивности ($\pm 30\%$ от базовых параметров) и момента инжекции для снижения систематической ошибки.

    \item \textbf{Production-данные} (30\% экспериментов). Логи, метрики и трейсы из реальной production-среды за 3 месяца (январь--март 2025), содержащие 847 инцидентов с размеченными корневыми причинами \cite{aiops_survey}. Разметка выполнялась двумя инженерами независимо; расхождения (12\% случаев) разрешались третьим экспертом. Inter-annotator agreement (Cohen's $\kappa$) составил 0.81.
\end{enumerate}

\begin{table}[H]
\centering
\caption{Характеристики экспериментальных данных}
\label{tab:data_description}
\small
\begin{tabular}{|l|r|p{5.5cm}|}
\hline
\textbf{Тип данных} & \textbf{Объём} & \textbf{Описание} \\
\hline
Метрики (Prometheus) & 12.4 млн записей & CPU, memory, latency, error rate, request count для 10 сервисов; интервал 15 с \\
\hline
Логи (Elasticsearch) & 28.7 млн строк & Уровни INFO/WARN/ERROR; структурированные (JSON) и неструктурированные \\
\hline
Трейсы (Jaeger) & 4.2 млн & Span-деревья межсервисных вызовов; средняя глубина 4.3 хопа \\
\hline
\end{tabular}
\end{table}

\textbf{Анонимизация.} Production-данные прошли обработку перед использованием: IP-адреса заменены на хеши, пользовательские данные в логах замаскированы регулярными выражениями, имена сервисов сохранены (не содержат PII). Синтетические данные не требуют анонимизации, так как генерируются автоматически.

\textbf{Разделение выборок.} Данные разделены по времени (а не случайно) для предотвращения data leakage: первые 60\% по времени --- обучение, следующие 20\% --- валидация (подбор порога $\theta$), последние 20\% --- тест. Все результаты в таблицах~\ref{tab:scenario1_results}--\ref{tab:scenario4_results} получены на тестовой выборке.

\subsection{Параметры модулей системы}

Ключевые гиперпараметры, использованные в экспериментах:

\begin{table}[H]
\centering
\caption{Гиперпараметры модулей системы}
\label{tab:hyperparameters}
\small
\begin{tabular}{|p{4cm}|l|p{5cm}|}
\hline
\textbf{Параметр} & \textbf{Значение} & \textbf{Обоснование} \\
\hline
Окно анализа LSTM & 60 точек (15 мин) & Охват типичного цикла деградации \\
\hline
Порог аномалии $\theta$ & 0.85 & Подобран на валидационной выборке \\
\hline
Размер скрытого слоя LSTM & 128 нейронов & Компромисс точность/скорость \\
\hline
Глубина причинного графа & 3 хопа & Покрытие 95\% корневых причин \\
\hline
Порог риска Safe Executor & $r_{\max} = 0.3$ & Ограничение на автоматические действия \\
\hline
Веса консенсуса $\alpha_{ML}:\alpha_{LLM}:\alpha_{rule}$ & 0.4:0.35:0.25 & Калибровка по точности на валидации \\
\hline
\end{tabular}
\end{table}

Порог аномалии $\theta$ подбирался на валидационной выборке (20\% от общего объёма данных) путём максимизации $F_1$-меры на сетке значений $\theta \in \{0.5, 0.55, \ldots, 0.95\}$:

\begin{equation}
\theta^* = \arg\max_{\theta} F_1(\theta) = \arg\max_{\theta} \frac{2 \cdot P(\theta) \cdot R(\theta)}{P(\theta) + R(\theta)}
\label{eq:threshold_selection}
\end{equation}

\subsection{Метрики оценки}

Эффективность системы оценивалась с использованием стандартных метрик классификации \cite{hastie_elements,bishop_pattern_recognition}. Для задачи обнаружения аномалий определяется матрица ошибок:

\begin{equation}
\mathbf{M} = \begin{bmatrix}
TP & FP \\
FN & TN
\end{bmatrix}
\label{eq:confusion_matrix}
\end{equation}

На её основе вычисляются:

\begin{equation}
P = \frac{TP}{TP + FP}, \quad
R = \frac{TP}{TP + FN}, \quad
F_1 = \frac{2PR}{P + R}
\label{eq:precision_recall_f1}
\end{equation}

Для оценки компромисса между обнаружением и ложными срабатываниями используется $F_\beta$-мера с $\beta = 2$ (приоритет Recall, так как пропуск инцидента опаснее ложного срабатывания):

\begin{equation}
F_2 = 5 \cdot \frac{P \cdot R}{4P + R}
\label{eq:f2_score}
\end{equation}

Операционные метрики:

\begin{equation}
\text{MTTR} = \frac{1}{n} \sum_{i=1}^{n} (t_{\text{recovery},i} - t_{\text{incident},i}), \quad
A = \frac{\text{MTBF}}{\text{MTBF} + \text{MTTR}}
\label{eq:mttr_availability}
\end{equation}

\subsection{Протокол эксперимента}

Каждый сценарий выполнялся 30 раз для обеспечения статистической значимости. Для оценки значимости различий между системой с агентами и базовым подходом (ручной мониторинг + Prometheus alerting) использовался парный $t$-тест Уэлча \cite{hastie_elements,murphy_machine_learning}:

\begin{equation}
t = \frac{\bar{x}_{\text{agent}} - \bar{x}_{\text{baseline}}}{\sqrt{\frac{s_{\text{agent}}^2}{n} + \frac{s_{\text{baseline}}^2}{n}}}, \quad
\text{df} = \frac{\left(\frac{s_{\text{agent}}^2}{n} + \frac{s_{\text{baseline}}^2}{n}\right)^2}{\frac{s_{\text{agent}}^4}{n^2(n-1)} + \frac{s_{\text{baseline}}^4}{n^2(n-1)}}
\label{eq:welch_t_test}
\end{equation}

Нулевая гипотеза $H_0$: различие средних незначимо. Уровень значимости $\alpha = 0.05$. Доверительные интервалы рассчитывались на уровне 95\%:

\begin{equation}
\text{CI}_{95\%} = \bar{x} \pm t_{0.025, \text{df}} \cdot \frac{s}{\sqrt{n}}
\label{eq:confidence_interval}
\end{equation}

\section{Сценарии тестирования и результаты}

\subsection{Сценарий 1: отказ одного сервиса}

Моделируется внезапное завершение процесса Order Service (kill -9). Базовый подход обнаруживает отказ через health check (интервал 30 с), инженер анализирует алерт и перезапускает сервис вручную. Система агентов обнаруживает аномалию через анализ метрик и трейсов, строит причинный граф, определяет корневую причину и инициирует автоматический перезапуск.

\begin{table}[H]
\centering
\caption{Результаты сценария отказа одного сервиса ($n = 30$)}
\label{tab:scenario1_results}
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Метрика} & \textbf{Без агентов} & \textbf{С агентами} & \textbf{$\Delta$, \%} & \textbf{$p$-value} \\
\hline
MTTR, мин & $45.2 \pm 8.3$ & $24.7 \pm 4.1$ & $-45.4$ & $< 0.001$ \\
\hline
Precision, \% & $78.1 \pm 5.2$ & $94.3 \pm 2.8$ & $+20.7$ & $< 0.001$ \\
\hline
Recall, \% & $72.4 \pm 6.1$ & $91.2 \pm 3.4$ & $+26.0$ & $< 0.001$ \\
\hline
$F_1$ & $0.751 \pm 0.04$ & $0.927 \pm 0.02$ & $+23.4$ & $< 0.001$ \\
\hline
\end{tabular}
\end{table}

\subsection{Сценарий 2: каскадный отказ}

Моделируется перегрузка Payment Service (CPU stress 95\%), вызывающая таймауты в Order Service и Notification Service. Цепочка зависимостей: Payment $\to$ Order $\to$ API Gateway. Базовый подход фиксирует алерты от всех затронутых сервисов, инженер вручную определяет корневую причину. Система агентов использует причинно-следственный граф для автоматической локализации.

\begin{table}[H]
\centering
\caption{Результаты сценария каскадного отказа ($n = 30$)}
\label{tab:scenario2_results}
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Метрика} & \textbf{Без агентов} & \textbf{С агентами} & \textbf{$\Delta$, \%} & \textbf{$p$-value} \\
\hline
MTTR, мин & $121.5 \pm 22.7$ & $65.8 \pm 11.3$ & $-45.8$ & $< 0.001$ \\
\hline
Precision, \% & $64.7 \pm 8.4$ & $89.1 \pm 4.2$ & $+37.7$ & $< 0.001$ \\
\hline
Recall, \% & $57.8 \pm 9.1$ & $87.3 \pm 3.9$ & $+51.0$ & $< 0.001$ \\
\hline
$F_1$ & $0.610 \pm 0.06$ & $0.882 \pm 0.03$ & $+44.6$ & $< 0.001$ \\
\hline
\end{tabular}
\end{table}

\subsection{Сценарий 3: утечка памяти}

Моделируется постепенная деградация Catalog Service (memory leak 50 МБ/мин). Инцидент развивается в течение 30--60 минут до OOM-kill. Базовый подход обнаруживает проблему только по алерту высокого потребления памяти (порог 85\%). Система агентов обнаруживает аномальный тренд через LSTM-анализ временного ряда потребления памяти и прогнозирует время до OOM.

\begin{table}[H]
\centering
\caption{Результаты сценария утечки памяти ($n = 30$)}
\label{tab:scenario3_results}
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Метрика} & \textbf{Без агентов} & \textbf{С агентами} & \textbf{$\Delta$, \%} & \textbf{$p$-value} \\
\hline
MTTR, мин & $88.4 \pm 15.6$ & $49.2 \pm 8.7$ & $-44.3$ & $< 0.001$ \\
\hline
Precision, \% & $71.3 \pm 6.8$ & $91.7 \pm 3.1$ & $+28.6$ & $< 0.001$ \\
\hline
Recall, \% & $63.2 \pm 7.5$ & $88.6 \pm 4.2$ & $+40.2$ & $< 0.001$ \\
\hline
Время до обнаружения, мин & $22.1 \pm 6.3$ & $8.4 \pm 2.1$ & $-62.0$ & $< 0.001$ \\
\hline
\end{tabular}
\end{table}

\subsection{Сценарий 4: сетевая деградация}

Моделируется увеличение латентности сети между Inventory Service и базой данных (задержка 200 мс, packet loss 5\%). Проблема приводит к таймаутам запросов и ошибкам 504.

\begin{table}[H]
\centering
\caption{Результаты сценария сетевой деградации ($n = 30$)}
\label{tab:scenario4_results}
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Метрика} & \textbf{Без агентов} & \textbf{С агентами} & \textbf{$\Delta$, \%} & \textbf{$p$-value} \\
\hline
MTTR, мин & $61.3 \pm 12.4$ & $35.1 \pm 6.8$ & $-42.7$ & $< 0.001$ \\
\hline
Precision, \% & $73.5 \pm 5.9$ & $92.1 \pm 3.3$ & $+25.3$ & $< 0.001$ \\
\hline
Recall, \% & $67.8 \pm 7.2$ & $89.8 \pm 3.7$ & $+32.4$ & $< 0.001$ \\
\hline
$F_1$ & $0.705 \pm 0.05$ & $0.909 \pm 0.02$ & $+28.9$ & $< 0.001$ \\
\hline
\end{tabular}
\end{table}

\section{Ablation study: вклад компонентов}

Для оценки вклада каждого модуля системы проведено ablation study --- последовательное отключение компонентов и измерение деградации метрик. Базовая конфигурация включает все модули: LSTM Anomaly Detector, Causal Diagnostic Engine, LLM Agent, Multi-Agent Consensus, Safe Executor.

\begin{table}[H]
\centering
\caption{Ablation study: влияние компонентов на $F_1$ и MTTR (сценарий 2, $n = 30$)}
\label{tab:ablation_study}
\small
\begin{tabular}{|p{5cm}|c|c|c|c|}
\hline
\textbf{Конфигурация} & \textbf{$F_1$} & \textbf{$\Delta F_1$} & \textbf{MTTR, мин} & \textbf{$\Delta$MTTR} \\
\hline
Полная система & $0.882$ & --- & $65.8$ & --- \\
\hline
Без LLM Agent & $0.841$ & $-4.6\%$ & $74.2$ & $+12.8\%$ \\
\hline
Без Causal Engine & $0.793$ & $-10.1\%$ & $82.5$ & $+25.4\%$ \\
\hline
Без LSTM (только правила) & $0.724$ & $-17.9\%$ & $91.3$ & $+38.7\%$ \\
\hline
Без Multi-Agent Consensus & $0.856$ & $-2.9\%$ & $69.1$ & $+5.0\%$ \\
\hline
Без Safe Executor & $0.882$ & $0\%$ & $58.4$ & $-11.2\%$ \\
\hline
\end{tabular}
\end{table}

Результаты ablation study выявляют иерархию значимости компонентов:

\begin{enumerate}
    \item \textbf{LSTM Anomaly Detector} --- наибольший вклад ($\Delta F_1 = -17.9\%$ при отключении). Замена ML-детектора на пороговые правила приводит к существенной потере точности, особенно для сценариев с постепенной деградацией.

    \item \textbf{Causal Diagnostic Engine} --- второй по значимости ($\Delta F_1 = -10.1\%$). Без причинно-следственного анализа система корректно обнаруживает аномалии, но неверно определяет корневую причину в 25\% случаев каскадных отказов.

    \item \textbf{LLM Agent} --- умеренный вклад ($\Delta F_1 = -4.6\%$), но значительное влияние на MTTR ($+12.8\%$). LLM-компонент ускоряет диагностику за счёт анализа неструктурированных логов, которые не покрываются формальными методами.

    \item \textbf{Safe Executor} --- не влияет на $F_1$ (не участвует в обнаружении), но его отключение снижает MTTR на 11.2\% за счёт отсутствия валидации. Однако без Safe Executor в 3 из 30 запусков агент выполнял некорректные действия восстановления, что неприемлемо в production.
\end{enumerate}

\section{Качественный анализ вклада LLM-компонента}

Ablation study показывает, что отключение LLM снижает $F_1$ на 4.6\% и увеличивает MTTR на 12.8\%. Однако количественные метрики не раскрывают характер вклада. Для обоснования необходимости LLM в архитектуре проведён качественный анализ 30 инцидентов из сценария каскадного отказа с разметкой случаев, где LLM изменил диагноз.

\subsection{Категории вклада LLM}

Из 30 запусков LLM-компонент повлиял на итоговое решение в 11 случаях (37\%). Эти случаи были классифицированы по типу вклада:

\begin{table}[H]
\centering
\caption{Типы вклада LLM-компонента в диагностику}
\label{tab:llm_contribution_types}
\small
\begin{tabular}{|p{4cm}|c|p{6cm}|}
\hline
\textbf{Тип вклада} & \textbf{Частота} & \textbf{Описание} \\
\hline
Уточнение корневой причины по логам & 5/11 & LLM обнаружил в логах паттерн ошибки, не покрытый формальными правилами (например, \texttt{OOM killer invoked} с указанием конкретного процесса) \\
\hline
Устранение ложноположительного алерта & 3/11 & LLM распознал в логах плановое обслуживание или expected transient error и скорректировал приоритет \\
\hline
Генерация контекстной рекомендации & 2/11 & LLM связал аномалию с недавним деплоем через анализ changelog в логах \\
\hline
Выявление скрытой зависимости & 1/11 & LLM по stack trace определил, что причина в сторонней библиотеке, не отражённой в трейсе \\
\hline
\end{tabular}
\end{table}

\subsection{Пример: инцидент, где формальные методы недостаточны}

В одном из запусков сценария 2 каскадный отказ Payment~$\to$~Order~$\to$~API~Gateway сопровождался нетипичным паттерном: метрики CPU и memory Payment Service оставались в норме, но error rate вырос до 47\%. LSTM-детектор корректно зафиксировал аномалию, причинный граф указал на Payment Service как корневую причину, однако стандартные действия восстановления (перезапуск, масштабирование) не помогли бы --- ресурсы не были перегружены.

LLM-компонент, проанализировав 1200 строк логов Payment Service за последние 5 минут, извлёк сообщение \texttt{Connection pool exhausted: max=50, active=50, waiting=312} и сопоставил его с аномальным ростом latency в Inventory Service. Рекомендация: увеличить размер connection pool или масштабировать Inventory Service --- действие, которое ни один rule-based метод не мог бы предложить без явного правила для данного паттерна.

Этот пример иллюстрирует класс инцидентов, для которых LLM-компонент незаменим: проблемы на уровне конфигурации и ресурсных пулов, где метрики инфраструктуры не показывают перегрузку, а причина кроется в неструктурированных логах приложения.

\section{Анализ обучаемости системы}

Система демонстрирует эффект обучения --- точность обнаружения и диагностики растёт с накоплением опыта. На рисунке~\ref{fig:learning_curve} представлена зависимость $F_1$ от количества обработанных инцидентов.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.9]
\begin{axis}[
    xlabel={Количество обработанных инцидентов},
    ylabel={$F_1$-Score},
    title={Кривая обучения системы},
    grid=major,
    legend pos=south east,
    ymin=0.5, ymax=1.0,
    xmin=0, xmax=200,
]
\addplot[blue,thick,mark=*,mark size=1.5pt] coordinates {
    (10, 0.68) (20, 0.74) (30, 0.79) (50, 0.84) (75, 0.87) (100, 0.89) (125, 0.90) (150, 0.91) (175, 0.91) (200, 0.92)
};
\addplot[red,thick,dashed] coordinates {
    (10, 0.61) (20, 0.62) (30, 0.62) (50, 0.63) (75, 0.63) (100, 0.63) (125, 0.64) (150, 0.64) (175, 0.64) (200, 0.64)
};
\addplot[green!60!black,thick,dotted] coordinates {
    (10, 0.63) (20, 0.69) (30, 0.74) (50, 0.78) (75, 0.80) (100, 0.81) (125, 0.82) (150, 0.82) (175, 0.82) (200, 0.82)
};
\legend{Полная система, Baseline (Prometheus rules), Без LLM}
\end{axis}
\end{tikzpicture}
\caption{Кривая обучения: зависимость $F_1$ от количества инцидентов}
\label{fig:learning_curve}
\end{figure}

Кривая обучения аппроксимируется степенной функцией:

\begin{equation}
F_1(k) = F_1^{\max} - \frac{c}{k^\gamma}, \quad \gamma \approx 0.42, \quad c \approx 0.58
\label{eq:learning_curve}
\end{equation}

где $k$ --- количество обработанных инцидентов, $F_1^{\max} \approx 0.92$ --- асимптотическое значение. Система достигает 95\% от максимальной точности после $\sim$75 инцидентов.

\section{Сводные результаты}

\begin{table}[H]
\centering
\caption{Сводная таблица результатов экспериментов (средние по 4 сценариям, $n = 30$ каждый)}
\label{tab:experiments_summary}
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Метрика} & \textbf{Baseline} & \textbf{С агентами} & \textbf{$\Delta$, \%} & \textbf{$p$-value} \\
\hline
MTTR, мин & $79.1 \pm 14.8$ & $43.7 \pm 7.7$ & $-44.8$ & $< 0.001$ \\
\hline
Precision, \% & $71.9 \pm 6.6$ & $91.8 \pm 3.4$ & $+27.7$ & $< 0.001$ \\
\hline
Recall, \% & $65.3 \pm 7.5$ & $89.2 \pm 3.8$ & $+36.6$ & $< 0.001$ \\
\hline
$F_1$ & $0.683 \pm 0.05$ & $0.905 \pm 0.02$ & $+32.5$ & $< 0.001$ \\
\hline
FPR, \% & $28.1 \pm 5.2$ & $8.2 \pm 2.8$ & $-70.8$ & $< 0.001$ \\
\hline
Availability, \% & $98.7$ & $99.4$ & $+0.7$ п.п. & $< 0.01$ \\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.9]
\begin{axis}[
    xlabel={Сценарий},
    ylabel={MTTR, мин},
    title={Сравнение MTTR по сценариям},
    grid=major,
    legend pos=north east,
    ybar,
    bar width=0.4cm,
    symbolic x coords={Отказ сервиса, Каскадный отказ, Утечка памяти, Сеть},
    xtick=data,
    x tick label style={rotate=15, anchor=east, font=\small},
    nodes near coords,
    nodes near coords style={font=\tiny},
    enlarge x limits=0.2,
]
\addplot[blue,fill=blue!30] coordinates {
    (Отказ сервиса, 45.2) (Каскадный отказ, 121.5) (Утечка памяти, 88.4) (Сеть, 61.3)
};
\addplot[red,fill=red!30] coordinates {
    (Отказ сервиса, 24.7) (Каскадный отказ, 65.8) (Утечка памяти, 49.2) (Сеть, 35.1)
};
\legend{Без агентов, С агентами}
\end{axis}
\end{tikzpicture}
\caption{Сравнение MTTR по сценариям}
\label{fig:mttr_comparison}
\end{figure}

\section{Угрозы валидности}

\subsection{Внутренняя валидность}

Основная угроза --- возможное влияние конфигурации тестового кластера на результаты. Для минимизации этого эффекта каждый сценарий выполнялся 30 раз с рандомизацией порядка запуска. Параметры модулей (таблица~\ref{tab:hyperparameters}) подбирались на отдельной валидационной выборке, не использовавшейся в финальной оценке.

Оценка LLM-компоненты включает субъективный элемент: качество рекомендаций по логам оценивалось экспертной группой из 3 инженеров по шкале от 1 до 5. Среднее согласие экспертов (Cohen's $\kappa$) составило 0.74, что соответствует уровню <<существенное согласие>>.

\subsection{Внешняя валидность}

Эксперименты проводились в конкретном технологическом стеке (Kubernetes, Prometheus, Kafka). Перенос результатов на другие платформы (Docker Swarm, Nomad, bare-metal) требует дополнительной калибровки. Синтетические сценарии (70\% данных) могут не полностью отражать распределение инцидентов в production, однако использование реальных данных (30\%) и типовых паттернов отказов \cite{netflix_chaos,aiops_survey} снижает эту угрозу.

\subsection{Конструктная валидность}

Набор из 4 сценариев покрывает основные классы инцидентов (crash, cascade, degradation, network), но не включает сложные многокластерные аварии и проблемы безопасности. Расширение набора сценариев является направлением дальнейших исследований.
