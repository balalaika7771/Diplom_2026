\chapter{Обоснование архитектурных решений}

Проектируемая система требует выбора из нескольких альтернатив по каждому архитектурному измерению: декомпозиция, модель сбора данных, стиль взаимодействия компонентов, подход к диагностике. Данная глава формализует критерии выбора и обосновывает принятые решения.

\section{Сводка архитектурных альтернатив}

Каждое архитектурное измерение представляет компромисс между конкурирующими свойствами. Таблица~\ref{tab:architecture_decisions} фиксирует выбор для проектируемой системы с указанием определяющих критериев.

\begin{table}[H]
\centering
\caption{Архитектурные решения проектируемой системы}
\label{tab:architecture_decisions}
\small
\begin{tabular}{|p{2.2cm}|p{2cm}|p{2cm}|p{4.5cm}|}
\hline
\textbf{Измерение} & \textbf{Альтернативы} & \textbf{Выбор} & \textbf{Обоснование} \\
\hline
Декомпозиция & Монолит, микросервисы & Микросервисы & Независимое масштабирование Anomaly Detector и LLM Agent; изоляция отказов между модулями \\
\hline
Сбор данных & Push, pull, гибрид & Push (Kafka) & Задержка push-модели $T_{\text{push}} = T_{\text{send}} + T_{\text{net}}$ ниже, чем pull: $T_{\text{pull}} = T_{\text{poll}}/2 + T_{\text{net}}$; для LSTM-детектора критична минимальная задержка доставки \\
\hline
Взаимодействие & Request-driven, event-driven & Event-driven & Слабая связанность через шину событий; отказ одного агента не блокирует остальных (глава~2, формула~(\ref{eq:cascade_failure})) \\
\hline
Диагностика & Rule-based, ML-based, гибрид & Гибрид & Баланс интерпретируемости и адаптивности (секция~\ref{sec:rule_vs_ml}) \\
\hline
\end{tabular}
\end{table}

\textbf{Микросервисная декомпозиция} выбрана не для целевой системы (которая и так является распределённой), а для самих агентов диагностики. Связанность модулей $\text{Coupling} = 0.24$ (глава~8) означает, что LSTM Anomaly Detector, Diagnostic Engine и LLM Agent могут масштабироваться и обновляться независимо. Это критично: инференс LLM требует GPU и горизонтально масштабируется иначе, чем CPU-bound Diagnostic Engine.

\textbf{Event-driven взаимодействие через Kafka} обеспечивает два преимущества. Во-первых, буферизация: при всплеске алертов события накапливаются в топике, а не теряются. Во-вторых, воспроизводимость: при расследовании инцидента можно переиграть поток событий. В прототипе (глава~10) Kafka используется как единая шина для метрик, логов и трейсов с корреляцией по \texttt{trace\_id}.

\section{Rule-based vs ML-based диагностика}
\label{sec:rule_vs_ml}

Rule-based диагностика использует набор правил $\mathcal{R} = \{r_1, \ldots, r_k\}$ вида <<если условие, то диагноз>>. Применение правила:
\begin{equation}
\text{Action} = \text{action}_j, \quad j = \arg\min_{i: \text{condition}_i(s) = \text{true}} \text{priority}(r_i)
\label{eq:rule_application_paradigm}
\end{equation}

ML-based диагностика обучает модель $M: \mathcal{S} \to \mathcal{D}$ на исторических данных:
\begin{equation}
M^* = \arg\min_{M} \sum_{(s, d) \in \mathcal{D}_{\text{train}}} L(M(s), d)
\label{eq:ml_training_paradigm}
\end{equation}

Компромисс формализуется через соотношение точности и стоимости поддержки:
\begin{equation}
\text{Efficiency} = \frac{\text{Accuracy}}{\text{SetupTime} + \text{MaintenanceTime}}
\label{eq:diagnosis_efficiency_paradigm}
\end{equation}

Для rule-based подхода $\text{MaintenanceTime} = O(k)$ --- линейно от числа правил; при добавлении новых сервисов требуется ручное написание правил. Для ML-based подхода $\text{MaintenanceTime} = O(|\mathcal{D}_{\text{new}}|)$ --- линейно от объёма новых данных; адаптация происходит автоматически через переобучение.

\begin{table}[H]
\centering
\caption{Сравнение подходов к диагностике}
\label{tab:diagnosis_approaches}
\small
\begin{tabular}{|p{2.5cm}|p{2.2cm}|p{2.2cm}|p{2.2cm}|}
\hline
\textbf{Критерий} & \textbf{Rule-based} & \textbf{ML-based} & \textbf{Гибрид (выбор)} \\
\hline
Интерпретируемость & Высокая & Низкая & Высокая для типичных случаев \\
\hline
Адаптивность & Нет & Да & Да \\
\hline
Время реакции & $< 1$ мс & $10$--$100$ мс & $< 1$ мс (rule) или $10$--$100$ мс (ML) \\
\hline
Масштабируемость & $O(k)$ правил вручную & Автоматическая & Автоматическая + ручные правила для критичных случаев \\
\hline
\end{tabular}
\end{table}

Гибридный подход комбинирует оба метода:
\begin{equation}
\text{Diagnosis} = \begin{cases}
\text{rule\_based}(s) & \text{если } \text{confidence}(\text{rule}) > \theta \\
\text{ml\_based}(s) & \text{иначе}
\end{cases}
\label{eq:hybrid_diagnosis_paradigm}
\end{equation}

В проектируемой системе гибридный подход реализуется следующим образом:
\begin{itemize}
    \item \textbf{Rule-based уровень}: Z-score пороги (глава~6) для известных паттернов отказов --- OOM-kill ($\text{memory} > 90\%$), disk full, certificate expiry. Эти правила обеспечивают мгновенную реакцию ($< 1$ мс) и полную интерпретируемость.
    \item \textbf{ML-based уровень}: LSTM Anomaly Detector (глава~6) для нетипичных паттернов --- каскадных отказов, медленной деградации, аномальных корреляций между метриками. Обнаруживает аномалии, которые невозможно описать статическими правилами.
    \item \textbf{LLM-уровень}: анализ неструктурированных логов (главы~6, 7) для случаев, когда причина кроется в конфигурации или логике приложения, а не в перегрузке ресурсов.
\end{itemize}

Ablation study (глава~11) подтверждает необходимость всех трёх уровней: отключение LSTM снижает $F_1$ на 17.9\%, LLM --- на 4.6\%. Из 11 инцидентов, разобранных в качественном анализе, LLM оказался критичен в 4 случаях (37\%), где числовые методы не могли определить корневую причину.

\section{Обоснование выбора event-driven архитектуры}

Отказоустойчивость event-driven архитектуры формализуется через сравнение с request-driven моделью. Для $n$ последовательных сервисов в request-driven цепочке:
\begin{equation}
R_{\text{request}} = \prod_{i=1}^{n} R_i = R^n
\label{eq:request_resilience_paradigm}
\end{equation}

В event-driven архитектуре с независимой обработкой:
\begin{equation}
R_{\text{event}} = 1 - \prod_{i=1}^{n}(1 - R_i) = 1 - (1 - R)^n
\label{eq:event_resilience_paradigm}
\end{equation}

При $R = 0.99$ и $n = 5$: $R_{\text{request}} = 0.951$, $R_{\text{event}} = 0.99999$. Для системы диагностики, где ложное молчание (пропуск аномалии) критичнее ложной тревоги, event-driven архитектура предпочтительна.

В прототипе (глава~10) это реализуется через Apache Kafka: каждый модуль (Anomaly Detector, Diagnostic Engine, LLM Agent) потребляет события из выделенных топиков и публикует результаты в downstream-топики. Отказ LLM Agent не останавливает работу Anomaly Detector --- диагностика продолжается без LLM-обогащения, с автоматическим восстановлением при возвращении модуля.

\medskip

Архитектурные решения --- микросервисная декомпозиция агентов, event-driven взаимодействие через Kafka, гибридная диагностика (rule + ML + LLM) --- определены требованиями к отказоустойчивости, задержке и адаптивности. Каждый выбор обоснован формальными критериями и верифицирован экспериментально (глава~11). Конкретная реализация этих решений описана в архитектуре системы (глава~8) и прототипе (глава~10).
