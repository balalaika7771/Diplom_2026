\chapter{Интеллектуальные автономные агенты и их архитектура}

\section{Автономный агент: определение и свойства}

Автономный агент --- программная система, способная действовать самостоятельно в заданной среде для достижения целей \cite{wooldridge_agents,multi_agent_systems}. В контексте распределённых систем агент анализирует метрики, логи и трейсы, обнаруживает проблемы, определяет их причины и принимает решения о восстановлении без участия оператора \cite{autonomous_agents_phd}.

Ключевые свойства агента:
\begin{itemize}
    \item Автономность --- способность действовать без прямого вмешательства человека
    \item Реактивность --- реагирование на изменения в среде в реальном времени
    \item Проактивность --- инициация действий для предотвращения инцидентов
    \item Социальность --- взаимодействие с другими агентами для координации решений
\end{itemize}

Математическая формулировка задачи: требуется функция принятия решений
\begin{equation}
  a^* = \arg\max_{a \in \mathcal{A}} U(s, a),
  \label{eq:decision_problem}
\end{equation}
где $\mathcal{A}$ --- пространство действий, $s$ --- текущее состояние системы, $U(s, a)$ --- функция полезности действия $a$ в состоянии $s$.

\section{Реактивные архитектуры}

Реактивные архитектуры основаны на цикле восприятие--решение--действие без построения сложных моделей среды \cite{agent_architectures}:
\begin{equation}
\text{Agent}(s_t) = \text{Act}(\text{Decide}(\text{Perceive}(s_t)))
\label{eq:reactive_agent}
\end{equation}

Время реакции:
\begin{equation}
T_{\text{reaction}} = T_{\text{perceive}} + T_{\text{decide}} + T_{\text{act}}
\label{eq:reaction_time}
\end{equation}

Для реактивных агентов $T_{\text{decide}} \ll T_{\text{planning}}$, что обеспечивает быстрое реагирование. Ограничение: реактивные агенты не учитывают долгосрочные последствия действий, что мотивирует гибридные архитектуры.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=1.2cm, auto, scale=0.75, transform shape, font=\small]
    \node[rectangle, draw, fill=blue!20, minimum width=1.2cm, minimum height=0.6cm] (sensor) {Sensor};
    \node[rectangle, draw, fill=green!20, right=of sensor, minimum width=1.2cm, minimum height=0.6cm] (processor) {Processor};
    \node[rectangle, draw, fill=yellow!20, below=of processor, minimum width=1.2cm, minimum height=0.6cm] (actuator) {Actuator};

    \draw[->, shorten >=2pt, shorten <=2pt] (sensor) -- (processor);
    \draw[->, shorten >=2pt, shorten <=2pt] (processor) -- (actuator);
    \draw[->, shorten >=2pt, shorten <=2pt] (actuator) -- (sensor);
\end{tikzpicture}
\caption{Архитектура реактивного агента \cite{wooldridge_agents,russell_artificial_intelligence}}
\label{fig:reactive_agent}
\end{figure}

\section{BDI-архитектура: целеполагание через убеждения, желания, намерения}

BDI-архитектура решает проблему целеполагания, отсутствующего в реактивных агентах \cite{bdi_architecture}. Агент оперирует тремя типами ментальных установок:
\begin{align}
B &= \{b_1, \ldots, b_n\}, \quad b_i: \mathcal{S} \to [0, 1] & \text{(убеждения)} \label{eq:beliefs} \\
D &= \{d_1, \ldots, d_m\}, \quad d_i: \mathcal{S} \to [0, 1] & \text{(желания)} \label{eq:desires} \\
I &= \{i_1, \ldots, i_k\}, \quad i_j: \mathcal{S} \times \mathcal{A} \to [0, 1] & \text{(намерения)} \label{eq:intentions}
\end{align}

Выбор намерения:
\begin{equation}
\text{Intention}^* = \arg\max_{i \in I} \left[ \text{Desire}(i) \cdot \text{Belief}(i) \cdot \text{Feasibility}(i) \right]
\label{eq:bdi_decision}
\end{equation}
где $\text{Desire}(i)$ --- желательность, $\text{Belief}(i)$ --- убеждённость в достижимости, $\text{Feasibility}(i) = P(\text{success}|i, s)$.

Байесовское обновление убеждений при поступлении нового наблюдения $o$:
\begin{equation}
P(b|o) = \frac{P(o|b) P(b)}{\sum_{b' \in B} P(o|b') P(b')}
\label{eq:belief_update}
\end{equation}

В проектируемой системе BDI-модель формализует поведение Diagnostic Engine: убеждения --- текущие показания метрик и результаты LSTM-детектора, желания --- восстановление нормального режима, намерения --- конкретные действия восстановления, проходящие через оценку риска (Safe Executor, глава~8).

\section{Оптимизация поведения: уравнение Беллмана}

Долгосрочная оптимизация поведения агента описывается функцией ценности состояния \cite{goodfellow_deep_learning,murphy_machine_learning}:
\begin{equation}
V(s) = \max_{a \in \mathcal{A}} \left[ R(s, a) + \gamma \sum_{s' \in \mathcal{S}} P(s'|s, a) V(s') \right]
\label{eq:bellman_equation}
\end{equation}
где $R(s, a)$ --- вознаграждение, $\gamma \in [0, 1]$ --- коэффициент дисконтирования, $P(s'|s, a)$ --- вероятность перехода.

Уравнение Беллмана~(\ref{eq:bellman_equation}) обосновывает, почему агент должен учитывать последствия действий: масштабирование узкого места (действие $a$) может разрешить текущий инцидент ($R > 0$), но создать каскадный эффект в будущем ($V(s') < 0$). В проектируемой системе это реализуется через критерий безопасности Safe Executor, который оценивает риск действия до его выполнения.

\textbf{Замечание.} Полное обучение с подкреплением (Q-learning, policy gradient) требует достаточного объёма данных об инцидентах для сходимости. В текущей версии системы используется эвристическая оценка $U(s, a)$ на основе экспертных весов, а переход к адаптивному обучению определён как направление развития (глава~13).

\section{Rule-based vs ML-based: гибридный подход}

Гибридный подход комбинирует правила и ML для баланса интерпретируемости и адаптивности:
\begin{equation}
\text{Action} = \begin{cases}
\text{rule\_based}(s) & \text{если } \text{confidence}(\text{rule}) > \theta_{\text{rule}} \\
\text{ml\_based}(s) & \text{иначе}
\end{cases}
\label{eq:hybrid_approach}
\end{equation}

Rule-based уровень обеспечивает мгновенную реакцию на известные паттерны ($T_{\text{rule}} < 1$ мс), ML-based уровень обнаруживает нетипичные аномалии через LSTM (глава~6). Детальное сравнение подходов и обоснование конкретных пропорций приведены в главе~9.

\section{LLM-агенты: анализ неструктурированных данных}

Значительная часть диагностической информации содержится в неструктурированных логах: сообщения об ошибках, стектрейсы, конфигурационные сообщения. Методы извлечения структурированной информации из логов описаны в главе~6 (формула~(\ref{eq:llm_extraction})). Здесь рассматривается интеграция LLM в цикл принятия решений агента.

LLM-агент анализирует логи, метрики и трейсы и генерирует рекомендации:
\begin{equation}
A = \text{LLM}(Q, L, \text{Context})
\label{eq:llm_qa}
\end{equation}
где $Q$ --- вопрос о проблеме, $L$ --- множество логов, $\text{Context}$ --- контекст о системе.

Трёхуровневый гибрид: комбинация rule-based, ML-based и LLM-based методов:
\begin{equation}
\text{Decision} = \begin{cases}
\text{rule-based}(s) & \text{если } \text{confidence}(\text{rule}) > \theta_{\text{rule}} \\
\text{ml-based}(s) & \text{если } \text{confidence}(\text{ml}) > \theta_{\text{ml}} \\
\text{llm-based}(s) & \text{иначе}
\end{cases}
\label{eq:hybrid_decision}
\end{equation}

Для объединения результатов используется ансамбль:
\begin{equation}
\text{Final Decision} = \sum_{i \in \{\text{rule}, \text{ml}, \text{llm}\}} w_i \cdot \text{Decision}_i
\label{eq:ensemble_decision}
\end{equation}
где $w_i$ --- веса методов, определяемые на основе их исторической точности.

Время принятия решения в гибридном подходе:
\begin{equation}
T_{\text{hybrid}} = \min(T_{\text{rule}}, T_{\text{ml}}) + P(\text{need\_llm}) \cdot T_{\text{llm}}
\label{eq:hybrid_time}
\end{equation}
где $P(\text{need\_llm})$ --- вероятность необходимости LLM-анализа. Это позволяет использовать быстрые методы для типичных случаев и LLM для сложных случаев, требующих контекстного анализа неструктурированных данных.

\section{Сравнение с существующими решениями AIOps}

Перед проектированием собственной архитектуры (глава~8) необходимо определить, какие решения уже существуют и в чём их ограничения.

\begin{table}[H]
\centering
\caption{Сравнение существующих AIOps-решений с предлагаемым подходом}
\label{tab:aiops_comparison}
\small
\begin{tabular}{|p{2.2cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{Система} & \textbf{Обнару\-жение} & \textbf{Причинный анализ} & \textbf{Авто\-восстанов\-ление} & \textbf{LLM-ана\-лиз логов} & \textbf{Безопас\-ность действий} \\
\hline
Prometheus + Alertmanager & Пороговые правила & Нет & Нет & Нет & Нет \\
\hline
Datadog Watchdog \cite{aiops_survey} & ML-ано\-малии & Частичный (корреляции) & Нет & Нет & Нет \\
\hline
Dynatrace Davis \cite{gartner_aiops} & ML + топология & Автомати\-ческий & Runbook-автома\-тизация & Нет & Частичная \\
\hline
IBM Cloud Pak for AIOps \cite{gartner_aiops} & ML-ансамбль & Графовый & Runbook & Базовый NLP & Нет \\
\hline
PagerDuty AIOps \cite{aiops_survey} & Статистика + ML & Корреляция алертов & Триггеры & Нет & Нет \\
\hline
\textbf{Предлага\-емая система} & \textbf{LSTM + ансамбль} & \textbf{Причинный граф + Грейнджер} & \textbf{Консенсус агентов} & \textbf{MCP + LLM} & \textbf{Safe Executor ($r_{\max}$)} \\
\hline
\end{tabular}
\end{table}

Анализ существующих решений выявляет три ключевых пробела:

\begin{enumerate}
    \item \textbf{Отсутствие замкнутого контура.} Большинство систем ограничиваются обнаружением и уведомлением. Dynatrace и IBM предлагают runbook-автоматизацию, но она требует заранее описанных сценариев и не адаптируется к нетипичным инцидентам.

    \item \textbf{Отсутствие формальной оценки безопасности.} Ни одно из решений не использует формальный критерий риска для валидации действий восстановления.

    \item \textbf{Отсутствие интеграции LLM для анализа логов.} IBM Cloud Pak использует базовый NLP, но не применяет LLM для генерации контекстных объяснений.
\end{enumerate}

Предлагаемый подход заполняет все три пробела: объединяет обнаружение (LSTM), причинно-следственную диагностику (граф + Грейнджер), контекстный анализ логов (LLM через MCP) и безопасное автовосстановление (Safe Executor) в единую архитектуру с консенсусом агентов.

\medskip

Формализованный в главе аппарат --- от реактивного цикла и BDI-целеполагания до гибридных ансамблей rule/ML/LLM --- определяет строительные блоки проектируемой системы. Сравнение с существующими AIOps-решениями подтверждает, что замкнутый контур <<обнаружение--диагностика--восстановление>> с формальной оценкой безопасности и LLM-анализом логов не реализован ни в одном из рассмотренных аналогов. Конкретная архитектура системы, использующая эти блоки, описана в главе~8.
