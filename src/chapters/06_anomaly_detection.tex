\chapter{Методы обнаружения аномалий и прогнозирования деградации}

\section{Постановка задачи}

Аномалия в распределённой системе --- статистически значимое отклонение наблюдаемого поведения от нормального режима \cite{anomaly_detection_survey,chandola_anomaly}. Формально: при наблюдении $\mathbf{x} \in \mathbb{R}^d$ требуется функция $f: \mathbb{R}^d \to \{0, 1\}$, классифицирующая наблюдение как аномальное или нормальное.

Основные проблемы пороговых методов мониторинга:
\begin{itemize}
    \item Статические пороги не учитывают нестационарность нормального поведения
    \item Одномерный анализ пропускает аномалии, проявляющиеся в корреляциях между метриками
    \item Ручная настройка порогов не масштабируется с ростом числа сервисов
\end{itemize}

В данной главе последовательно рассматриваются методы с возрастающей сложностью, обосновывается выбор комбинации для проектируемой системы.

\section{Статистические методы}

Простейший подход: Z-score для нормально распределённой метрики $X \sim \mathcal{N}(\mu, \sigma^2)$ \cite{hastie_elements,murphy_machine_learning}:
\begin{equation}
z = \frac{x - \mu}{\sigma}, \quad |z| > k \Rightarrow \text{аномалия}, \quad P(|Z| > 3) \approx 0.0027
\label{eq:z_score}
\end{equation}

\textbf{Ограничения:} предполагает нормальность распределения и независимость наблюдений. Метрики распределённых систем (latency, error rate) часто имеют тяжёлые хвосты и автокорреляцию, что делает Z-score непригодным как единственный метод. В проектируемой системе Z-score используется как быстрый фильтр первого уровня для rule-based компонента, а не как основной детектор.

\section{Временные ряды и ARIMA}

Метрики образуют нестационарные временные ряды \cite{time_series_anomaly,acm_anomaly_detection}. ARIMA$(p,d,q)$ моделирует автокорреляционную структуру \cite{hastie_elements}:
\begin{equation}
(1 - \sum_{i=1}^{p} \phi_i B^i)(1-B)^d y_t = (1 + \sum_{i=1}^{q} \theta_i B^i)\epsilon_t
\label{eq:arima}
\end{equation}
где $B$ --- оператор сдвига, $\phi_i, \theta_i$ --- параметры модели.

Аномалия обнаруживается при значительном отклонении факта от прогноза:
\begin{equation}
|y_{T+h} - \hat{y}_{T+h}| > k \cdot \sigma_{\text{forecast}}
\label{eq:arima_anomaly}
\end{equation}

\textbf{Ограничения:} ARIMA --- линейная модель, не улавливающая нелинейные зависимости между метриками. Для каскадных отказов, где деградация одного сервиса нелинейно влияет на другие через граф зависимостей, ARIMA недостаточен. Это мотивирует использование нейросетевых методов.

\section{Isolation Forest: многомерное обнаружение}

Isolation Forest \cite{isolation_forest} решает проблему многомерности: аномалии изолируются за меньшее число случайных разбиений, чем нормальные точки. Оценка аномальности:
\begin{equation}
s(x, n) = 2^{-E[h(x)]/c(n)}
\label{eq:isolation_forest}
\end{equation}
где $E[h(x)]$ --- средняя глубина изоляции по ансамблю деревьев, $c(n) = 2H(n-1) - 2(n-1)/n$ --- нормализующая константа.

Интерпретация: $s \approx 1$ --- аномалия, $s \approx 0.5$ --- нормальная точка.

\textbf{Преимущества:} не требует предположений о распределении, работает с многомерными данными, линейная сложность $O(n \log n)$. \textbf{Ограничения:} не учитывает временные зависимости --- каждое наблюдение анализируется независимо. Для постепенной деградации (memory leak, рост latency) требуется модель с памятью.

\section{LSTM: долгосрочные зависимости во временных рядах}

LSTM \cite{goodfellow_deep_learning,lstm_time_series} решает проблему затухающих градиентов в рекуррентных сетях через механизм ячеек с воротами:
\begin{align}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) & \text{(забывающий гейт)} \label{eq:lstm_forget} \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) & \text{(гейт входа)} \label{eq:lstm_input} \\
C_t &= f_t \odot C_{t-1} + i_t \odot \tanh(W_C [h_{t-1}, x_t] + b_C) & \text{(состояние ячейки)} \label{eq:lstm_cell_state} \\
h_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \odot \tanh(C_t) & \text{(скрытое состояние)} \label{eq:lstm_hidden}
\end{align}

Предсказание: $\hat{x}_{t+1} = W_y h_t + b_y$. Аномалия определяется по ошибке предсказания:
\begin{equation}
\text{Anomaly}(x_t) = \mathbf{1}[|x_t - \hat{x}_t| > \mu_e + k\sigma_e]
\label{eq:lstm_anomaly}
\end{equation}
где $\mu_e, \sigma_e$ --- статистики ошибок на обучающей выборке.

\textbf{Обоснование выбора LSTM для проектируемой системы.} Сравнение подходов:

\begin{table}[H]
\centering
\caption{Сравнение методов обнаружения аномалий}
\label{tab:anomaly_methods_comparison}
\small
\begin{tabular}{|p{2.5cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{2.5cm}|}
\hline
\textbf{Метод} & \textbf{Многомер\-ность} & \textbf{Временные зависим.} & \textbf{Нелиней\-ность} & \textbf{Сложность} \\
\hline
Z-score & Нет & Нет & Нет & $O(1)$ \\
\hline
ARIMA & Частично & Да & Нет & $O(np)$ \\
\hline
Isolation Forest & Да & Нет & Да & $O(n \log n)$ \\
\hline
\textbf{LSTM} & \textbf{Да} & \textbf{Да} & \textbf{Да} & $O(Td^2)$ \\
\hline
\end{tabular}
\end{table}

LSTM --- единственный метод, одновременно учитывающий многомерность, временные зависимости и нелинейность. Цена --- вычислительная сложность $O(Td^2)$, где $T$ --- длина окна, $d$ --- размерность. В проектируемой системе используется ансамбль: LSTM как основной детектор, Isolation Forest для кросс-валидации, Z-score для быстрых rule-based проверок.

\section{Прогнозирование деградации}

Превентивное обнаружение требует прогноза до достижения критического состояния. Вероятность деградации на горизонте $\Delta t$ \cite{hastie_elements,bishop_pattern_recognition}:
\begin{equation}
P(\text{degradation}|t+\Delta t) = \sigma\left(\sum_{i=1}^{n} w_i \cdot \frac{dm_i(t)}{dt} + w_0\right)
\label{eq:degradation_prediction}
\end{equation}
где $dm_i/dt$ --- скорость изменения метрики $i$, $w_i$ --- веса, обученные на исторических инцидентах.

Критерий деградации:
\begin{equation}
\text{Degradation}(t+\Delta t) = \mathbf{1}[\exists i: \hat{m}_i(t+\Delta t) > \theta_i \;\lor\; P(\text{degradation}|t+\Delta t) > \theta_p]
\label{eq:degradation_criterion}
\end{equation}

В экспериментах (глава~11, сценарий 3) прогнозирование деградации позволяет обнаружить утечку памяти за 8.4 мин до OOM-kill, тогда как пороговый мониторинг --- за 22.1 мин (сокращение на 62\%).

\section{LLM-анализ логов}

Числовые методы работают с метриками, но значительная часть диагностической информации содержится в текстовых логах: сообщения об ошибках, стектрейсы, конфигурационные сообщения. LLM \cite{goodfellow_deep_learning} извлекает структурированную информацию из неструктурированных логов:
\begin{equation}
\text{StructuredInfo}(L) = \{(e_j, t_j, p_j) : e_j \in E, t_j \in T, p_j \in [0, 1]\}
\label{eq:llm_extraction}
\end{equation}
где $E$ --- типы сущностей (сервисы, ошибки, метрики), $p_j$ --- уверенность.

Интеграция с числовыми методами через взвешенную оценку:
\begin{equation}
\text{Anomaly Score} = w_{\text{metrics}} \cdot \text{Score}_{\text{metrics}} + w_{\text{logs}} \cdot \text{Score}_{\text{llm}} + w_{\text{traces}} \cdot \text{Score}_{\text{traces}}
\label{eq:llm_integration}
\end{equation}

Качественный анализ (глава~11) показывает, что LLM критичен в 37\% инцидентов --- случаях, когда причина кроется не в перегрузке ресурсов, а в конфигурации или ресурсных пулах приложения, информация о которых доступна только в логах.

\medskip

Рассмотренные методы образуют иерархию: от одномерных статистических критериев до многомерных нейросетевых моделей и LLM-анализа неструктурированных данных. В проектируемой системе они комбинируются в ансамбль (глава~8): LSTM обеспечивает основное обнаружение, Isolation Forest --- кросс-валидацию, LLM --- анализ контекста из логов. Выбор комбинации обосновывается ablation study (глава~11): отключение LSTM снижает $F_1$ на 17.9\%, Diagnostic Engine --- на 10.1\%, LLM --- на 4.6\%.
