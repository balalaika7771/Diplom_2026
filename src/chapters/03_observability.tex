\chapter{Observability как фундамент диагностики}

\section{Наблюдаемость и её формализация}

Наблюдаемость системы определяется как способность по доступным выходным данным восстановить её внутреннее состояние \cite{charity_majors_observability,observability_three_pillars}. В отличие от классического мониторинга (пороговые алерты на отдельных метриках), наблюдаемость предполагает возможность реконструировать цепочку событий и установить причинно-следственные связи \cite{three_pillars,observability_vs_monitoring}.

Формально, для линейной системы $\dot{x}(t) = Ax(t) + Bu(t)$, $y(t) = Cx(t)$ наблюдаемость определяется полнотой ранга матрицы наблюдаемости:
\begin{equation}
\text{rank}(\mathcal{O}) = \text{rank}\begin{bmatrix} C \\ CA \\ \vdots \\ CA^{n-1} \end{bmatrix} = n
\label{eq:observability_matrix}
\end{equation}

Для нелинейных распределённых систем полная наблюдаемость недостижима: число внутренних переменных растёт с числом сервисов, а сенсоры (метрики, логи, трейсы) покрывают лишь проекции состояния. Эта неполнота определяет необходимость комбинирования нескольких типов данных.

\section{Три столпа: метрики, логи, трейсы}

Наблюдаемость обеспечивается тремя взаимодополняющими типами данных \cite{observability_three_pillars,ieee_observability}.

\textbf{Метрики} $M(t)$ представляют числовые проекции состояния: $M(t) = \pi_M(x(t)) \in \mathbb{R}$. Типы метрик (counter, gauge, histogram) определяют доступные операции агрегации. Ключевое ограничение --- потеря информации при агрегации. Решение --- использование процентилей:
\begin{equation}
P_p = \inf\{x : F(x) \geq p\}, \quad p \in \{0.50, 0.95, 0.99\}
\label{eq:percentile}
\end{equation}

Для агентов обнаружения аномалий это означает, что средние значения метрик недостаточны; LSTM-детектор (глава~6) работает с $P_{95}$ и $P_{99}$ latency как с более информативными сигналами.

\textbf{Логи} $L(t) = \{l_1, l_2, \ldots, l_k\}$ представляют последовательности событий с временными метками, типами и контекстом. Структурированные логи (JSON) допускают машинный анализ; неструктурированные требуют NLP-обработки. LLM-компонент системы (главы~7, 8) использует именно неструктурированные логи для извлечения диагностической информации, недоступной числовым методам.

\textbf{Трейсы} $T(t)$ --- деревья spans, представляющие пути запросов через систему \cite{distributed_tracing,distributed_tracing_survey}:
\begin{equation}
s_i = (\text{service}_i, t_{\text{start},i}, t_{\text{end},i}, \text{status}_i, \text{parent}_i)
\label{eq:span_tuple}
\end{equation}

Критический путь определяет узкое место обработки запроса:
\begin{equation}
\text{critical\_path} = \arg\max_{\text{path} \in \text{paths}(T)} \sum_{s_i \in \text{path}} \text{duration}_i
\label{eq:critical_path}
\end{equation}

Для модуля Diagnostic Engine (глава~8) трейсы предоставляют топологию зависимостей: отношение parent--child между spans определяет направление рёбер в причинно-следственном графе.

\begin{table}[H]
\centering
\caption{Сравнение типов данных наблюдаемости для задач агента}
\label{tab:observability_pillars}
\small
\begin{tabular}{|p{1.8cm}|p{2.5cm}|p{2.5cm}|p{4cm}|}
\hline
\textbf{Тип} & \textbf{Сильные стороны} & \textbf{Ограничения} & \textbf{Использование в системе} \\
\hline
Метрики & Числовые, агрегируемые, малый объём & Потеря контекста при агрегации & LSTM Anomaly Detector: обнаружение аномалий \\
\hline
Логи & Богатый контекст, семантика ошибок & Неструктурированность, большой объём & LLM Agent: анализ неструктурированных данных \\
\hline
Трейсы & Топология зависимостей, латентность по сервисам & Sampling снижает покрытие & Diagnostic Engine: построение причинного графа \\
\hline
\end{tabular}
\end{table}

\section{Причинно-следственные графы}

Для определения корневой причины инцидента строится причинно-следственный граф $G_{\text{causal}} = (V, E)$ на основе всех трёх типов данных \cite{distributed_tracing_survey}. Вероятность причинной связи определяется тремя признаками:
\begin{equation}
P(e_i \to e_j | \mathbf{m}, \mathbf{l}, \mathbf{t}) = \sigma\left(\sum_{k} w_k \cdot f_k(e_i, e_j, \mathbf{m}, \mathbf{l}, \mathbf{t})\right)
\label{eq:causal_probability}
\end{equation}
где $f_{\text{time}}$ --- временная близость, $f_{\text{corr}}$ --- корреляция метрик, $f_{\text{trace}}$ --- зависимость в трейсе, $\sigma$ --- сигмоидальная функция.

Рёбра включаются в граф при подтверждении причинности по критерию Грейнджера \cite{distributed_tracing_survey}:
\begin{equation}
e_j \text{ causes } e_i \Leftrightarrow \text{var}(\epsilon_{i|e_j}) < \text{var}(\epsilon_{i|\neg e_j})
\label{eq:granger_causality}
\end{equation}

Корневая причина определяется как вершина с минимальным входящим и ненулевым исходящим степенями:
\begin{equation}
\text{RootCause} = \arg\min_{v \in V} \text{in-degree}(v), \quad \text{out-degree}(v) > 0, \quad P(\text{anomaly}|v) > \theta
\label{eq:root_cause_search}
\end{equation}

Этот алгоритм реализуется в модуле Diagnostic Engine (глава~8) и верифицируется в экспериментах (глава~11): точность определения корневой причины составляет 89.1\% на каскадных сценариях.

\section{Ограничения существующих стеков}

Prometheus (pull-модель) \cite{prometheus_paper,prometheus_docs} масштабируется линейно по числу источников: $T_{\text{collection}} = \sum_{i=1}^{N} (T_{\text{poll},i} + T_{\text{network},i})$. При $N > 10^4$ источников интервал scrape становится сопоставимым с периодом сбора, что ограничивает гранулярность данных для агентов.

Объём данных растёт экспоненциально:
\begin{equation}
V(t) = V_0 \cdot e^{\lambda t}
\label{eq:storage_growth}
\end{equation}

Downsampling снижает объём, но ухудшает калибровку порогов обнаружения аномалий (Z-score и LSTM, глава~6).

Ключевое архитектурное ограничение: метрики, логи и трейсы хранятся в разных системах (Prometheus, Elasticsearch, Jaeger), что требует корреляции по trace\_id:
\begin{equation}
\text{UnifiedModel}(t) = \text{Join}(\text{Metrics}(t), \text{Logs}(t), \text{Traces}(t), \text{key} = \text{trace\_id})
\label{eq:unified_model}
\end{equation}

В прототипе (глава~10) эта корреляция реализуется через единую шину событий Kafka, куда все три типа данных направляются с общим trace\_id.

\medskip

Метрики, логи и трейсы формируют взаимодополняющие представления поведения системы. Однако ограничения существующих стеков --- линейное масштабирование pull-модели, раздельное хранение, отсутствие автоматической корреляции --- делают ручной анализ неэффективным при росте числа сервисов. Это мотивирует разработку автоматизированных методов диагностики, реализуемых через автономных агентов.
